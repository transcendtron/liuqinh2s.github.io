---
layout: post
title: 百度贴吧ID挖掘机
categories: 项目
tags: [爬虫, Python, 编程]
comments: true
---

去年我开了一个minecraft服务器，想拉点人进去玩，就想到要出去打广告啊，怎么办呢，我的好朋友[lianera](http://lianera.com)就跟我说，他以前在贴吧里面批量@别人，嗯，这是个不错的方法，他当时还给我看了他写的一个百度贴吧ID挖掘机，但不是用python写的，[第一版C语言](https://github.com/lianera/archives/tree/master/tieba-digger)，[第二版java](https://github.com/lianera/archives/tree/master/tbot)。不过后来这件事没有做成，因为现在百度贴吧禁止批量@了。

后来我就想学点python，因为据说python代码特别简洁，这对于我这种极简主义者是很有诱惑力的，正所谓--“人生苦短，我用python”（来源于：life is short, you need python）。另外python爬虫很有名啊，python玩数据很方便啊。数据时代怎么能不玩数据呢！于是我就一门心思想学python（其实还有一个原因，因为xx-net（一款翻墙软件）是用python写的，迟迟不出移动端的，我的手机也要翻墙啊，摔！我打算自己把xx-net移植到ios和安卓上，首先需要读懂代码啊，所以我还是需要学python，但后来lianera找了个便宜的VPS，并搭了shadowsocks服务，我们就一起用他搞的VPS翻墙了。。。）。

想着不能光看python语法而不做实事，我就重新造这个百度贴吧ID挖掘机轮子了。

先推荐[我的github](https://github.com/liuqinh2s)欢迎各位follow和指教，（程序员之间多多联系还是有必要的，大家可以讨论技术啊，除了技术还可以聊人生啊，电影啊，抱歉我以前是个文青，文科成绩一直很好，嗯，也爱科学）。

项目地址：[https://github.com/liuqinh2s/Python](https://github.com/liuqinh2s/Python)

一开始我是用python2，然后想着python3才是未来，然后就想改点代码就升级了呗，但是python2和python3真的是有点不一样，改得有点蛋疼，不过最后还是弄好了。

代码写的不好的地方请指出来哈。

下面我讲讲思路：

1. 首先定义了一个BaiDuTieBa类，用来获取HTML源代码，然后用正则表达式匹配抽取出用户ID，然后我用了一个全局的dict变量存放ID，最后把dict中的ID全部写入文件就可以啦。其中必不可少的到用到urllib库，re（regex, regular expression，正则表达式）库。
2. 然后我就想啊，单线程爬的这么慢简直不能忍，于是就搞个多线程吧，至少把我的网速和带宽占的满满的。这里我使用了任务队列和线程池，简单讲就是把任务都放进任务队列里面，然后线程放线程池里面，线程呢不断的去取任务，做完一个取一个，直到任务队列为空。线程池代码是从网上借鉴来的，管他呢自己改改能用就OK。这里用了threading库，queue库。

然后爬的时候，你看看自己的网络，反正我的是瞬间飙升到几兆每秒了，哈哈。

代码很初级，关键的地方都有注释哦，看不懂的地方私信我，我会在文章最后贴出常见的问题，并详细讲解。


```python
#!/usr/bin/env python3
# coding=utf-8

'''
    这是python3版本的，看文件名，TieBaID3.py，这个3啊就是python3，懂了伐。
'''

__author__ = 'liuqin'

import urllib.request
import re
import threading
import queue

IDdict = {}
#百度贴吧爬取用户ID，以minecraft吧为例
class BaiDuTieBa():
    def __init__(self, kw, pn):
        self.baseurl = "http://tieba.baidu.com/f/like/manage/list?"
        self.userAgent = "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.95 Safari/537.36"
        self.headers = {'User-Agent': self.userAgent}
        self.kw = kw
        self.pn = pn
        self.IDdict = IDdict

    def getHTML(self):
        url = self.baseurl + 'kw=' + self.kw + '&' + 'pn=' + str(self.pn)
        request = urllib.request.urlopen(url)
        # 注意这里网页源码编码是：GBK，用decode解码时要选择gbk
        pageHTML = request.read().decode('gbk')
        return pageHTML

    def getUserID(self):
        regex = re.compile('.*?username="(.*?)".*?')
        pageHTML = self.getHTML()
        UserID = re.findall(regex, pageHTML)
        return UserID

    def writeIDinDict(self):
        UserID = self.getUserID()
        count = 0
        for id in UserID:
            count += 1
            self.IDdict[count + self.pn * 20] = id

    def start(self):
        self.getUserID()
        self.writeIDinDict()
        print(u'写入第%d页用户ID' % (self.pn))


def writeInFile():
    file = open(u'./百度贴吧minecraft吧用户ID.txt', 'a+', encoding='UTF-8')
    # print(file.encoding)
    for i in IDdict:
        file.write(IDdict[i]+'\n')
    file.close()


#具体要做的任务
def do_job(kw, pn):
    spider = BaiDuTieBa(kw, pn)
    spider.start()

def do_job1(kw, pn):
    spider = BaiDuTieBa(kw, pn)
    return spider

# 单线程爬虫
def NoThreads(kw, pn):
    for i in range(1, pn+1):
        do_job(kw, i)


# 即时创建即时销毁多线程，这种有点太恐怖，有多少任务就创建多少线程，哈哈，任务数太多就爆炸了
class Thread_spider(threading.Thread):

    def __init__(self, kw, pn):
        threading.Thread.__init__(self)
        self.pn = pn
        self.kw = kw
    def run(self):
        do_job(self.kw, self.pn)

def MultiThreads(kw, pn):
    threads1 = [Thread_spider(kw, i) for i in range(1, pn+1)]
    for i in threads1:
        i.start()
    for i in threads1:
        if i.is_alive: i.join()


# 用线程池和任务队列
class WorkManager(object):# 这是一个线程管理器
    def __init__(self, kw, work_num, thread_num):
        self.task_queue = queue.Queue()
        self.threads = []
        self.kw = kw
        self.__init_task_queue(work_num)
        self.__init_thread_pool(thread_num)
        self.start_task()

    """
        添加一项工作入队
    """
    def add_job(self, func):
        self.task_queue.put(func)  # 任务入队，Queue内部实现了同步机制

    """
        初始化任务队列
    """
    def __init_task_queue(self, jobs_num):
        for i in range(1, jobs_num + 1):
            self.add_job(do_job1(self.kw, i))

    """
        初始化线程池
    """
    def __init_thread_pool(self,thread_num):
        for i in range(1,thread_num+1):
            self.threads.append(Work(self.task_queue))

    """
        开始执行任务
    """
    def start_task(self):
        for i in self.threads:
            i.setDaemon(1)
            i.start()

    """
        等待所有线程运行完毕
    """
    def wait_allcomplete(self):
        for item in self.threads:
            item.join(1)  

class Work(threading.Thread):# 这是线程类

    def __init__(self, task_queue):
        threading.Thread.__init__(self)
        self.task_queue = task_queue

    def run(self):
        while not self.task_queue.empty():
            self.task_queue.get().start()# 任务异步出队，Queue内部实现了同步机制
            self.task_queue.task_done()  # 通知系统任务完成


if __name__ == '__main__':
    kw = 'minecraft'  # 贴吧名称
    pn = 1000 # 页面数
    # 不用多线程模式
    # NoThreads(kw, pn)

    # 即时创建即时销毁，多线程模式
    # MultiThreads(kw, pn)

    # 任务队列线程池模式：（任务数：1000，线程：100）
    threads_num = 100
    work_manager =  WorkManager(kw, pn, threads_num)
    work_manager.wait_allcomplete()

    print("hello world")
    writeInFile()
```
